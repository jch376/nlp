{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Examples for Text Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use Python to pre-process text. There are a number of libraries that make this easier, notably:\n",
    "\n",
    "- NLTK (Natural Language Tool Kit)\n",
    "- TextBlob\n",
    "\n",
    "The documentation for TextBlob is [here](https://textblob.readthedocs.io/en/dev/) and NLTK is [here](https://www.nltk.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from textblob import TextBlob\n",
    "\n",
    "texts = ['ball pitch goal corner keeper kick pass run referee',\n",
    "        'ball pass scrum maul lineout kick goal fullback',\n",
    "        'net pass serve set rotate net block hit libero ball',\n",
    "        'court wing pass circle goal umpire quarter ball']\n",
    "\n",
    "doclist = []\n",
    "for text in texts:\n",
    "    doc = TextBlob(text)\n",
    "    doclist.append(doc.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['ball', 'pitch', 'goal', 'corner', 'keeper', 'kick', 'pass', 'run', 'referee'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doclist[0].words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Term Frequency - Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Term Frequency - Inverse Document Frequency (TF-IDF) is a weighting that finds words that are characteristic of a particular document within a corpus. It finds words that appear quite frequently in a given document, but not in the other documents. If we are interested in information retrieval or finding topics in documents then tf-idf is a useful way to weight terms.\n",
    "\n",
    "Words that occur only once or twice in a single document and not in any other documents don't tell us a lot about the document - they may be just the whim of the writer. Similarly, words that appear a lot in all the documents don't tell us much about the differences between documents.\n",
    "\n",
    "**Notes:**  \n",
    "TF-IDF code adapted from Steven Loria: http://stevenloria.com/finding-important-words-in-a-document-using-tf-idf/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: textblob in /opt/miniconda/lib/python3.7/site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in /opt/miniconda/lib/python3.7/site-packages (from textblob) (3.4.4)\n",
      "Requirement already satisfied: six in /opt/miniconda/lib/python3.7/site-packages (from nltk>=3.1->textblob) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# install textblob library if not already installed\n",
    "pip install textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definitions\n",
    "\n",
    "For each word in the corpus:\n",
    "\n",
    "**Term Frequency** (tf) = frequency of the word in each document\n",
    "\n",
    "**Document Frequency** (df) = number of documents in the corpus containing the word\n",
    "\n",
    "**Inverse Document Frequency** (idf) = (logarithm of) the number of documents divided by the document frequency for the word\n",
    "\n",
    "So tf-idf for a word in the corpus is calculated by tf * idf\n",
    "\n",
    "#### Interpretation\n",
    "\n",
    "A _high_ tf-idf score for a word means the term is fairly frequent in the corpus but not dispersed across many documents\n",
    "\n",
    "A _low_ tf-idf score for a word means the term is fairly infrequent in the corpus or is frequent but dispersed across many documents\n",
    "\n",
    "Tf-idf scores are relative to a corpus. Adding more documents will change the weightings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here are function definitions for tf, df, idf and tfidf.\n",
    "In practice the idf score usually uses 1 + df and then adds 1 to the result \n",
    "'''\n",
    "\n",
    "import math\n",
    "\n",
    "def tf(word, doc):\n",
    "    return doc.words.count(word) / len(doc.words)\n",
    "\n",
    "def df(word, doclist):\n",
    "    return sum(1 for doc in doclist if word in doc.words)\n",
    "\n",
    "def idf(word, doclist):\n",
    "    return math.log(len(doclist) / (df(word, doclist)))\n",
    "\n",
    "def tfidf(word, doc, doclist):\n",
    "    return tf(word, doc) * idf(word, doclist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words in document 1 (ball pitch goal corn...)\n",
      "\tpitch, TF-IDF: 0.15403\n",
      "\tcorner, TF-IDF: 0.15403\n",
      "\tkeeper, TF-IDF: 0.15403\n",
      "\trun, TF-IDF: 0.15403\n",
      "\treferee, TF-IDF: 0.15403\n",
      "\tkick, TF-IDF: 0.07702\n",
      "\tgoal, TF-IDF: 0.03196\n",
      "\tball, TF-IDF: 0.0\n",
      "\tpass, TF-IDF: 0.0\n",
      "Top words in document 2 (ball pass scrum maul...)\n",
      "\tscrum, TF-IDF: 0.17329\n",
      "\tmaul, TF-IDF: 0.17329\n",
      "\tlineout, TF-IDF: 0.17329\n",
      "\tfullback, TF-IDF: 0.17329\n",
      "\tkick, TF-IDF: 0.08664\n",
      "\tgoal, TF-IDF: 0.03596\n",
      "\tball, TF-IDF: 0.0\n",
      "\tpass, TF-IDF: 0.0\n",
      "Top words in document 3 (net pass serve set r...)\n",
      "\tnet, TF-IDF: 0.27726\n",
      "\tserve, TF-IDF: 0.13863\n",
      "\tset, TF-IDF: 0.13863\n",
      "\trotate, TF-IDF: 0.13863\n",
      "\tblock, TF-IDF: 0.13863\n",
      "\thit, TF-IDF: 0.13863\n",
      "\tlibero, TF-IDF: 0.13863\n",
      "\tpass, TF-IDF: 0.0\n",
      "\tball, TF-IDF: 0.0\n",
      "Top words in document 4 (court wing pass circ...)\n",
      "\tcourt, TF-IDF: 0.17329\n",
      "\twing, TF-IDF: 0.17329\n",
      "\tcircle, TF-IDF: 0.17329\n",
      "\tumpire, TF-IDF: 0.17329\n",
      "\tquarter, TF-IDF: 0.17329\n",
      "\tgoal, TF-IDF: 0.03596\n",
      "\tpass, TF-IDF: 0.0\n",
      "\tball, TF-IDF: 0.0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Here we loop through the list of documents called 'doclist'.\n",
    "Scores is a dictionary of key:value pairs. \n",
    "Each key is a word in the document and the value is its tfidf score. \n",
    "Results are sorted by the tfidf score with the largest value at the top.\n",
    "Lastly we print some results for each document.\n",
    "'''\n",
    "\n",
    "for i, doc in enumerate(doclist):\n",
    "    print(\"Top words in document {}\".format(i + 1), \"({}...)\".format(doc[:20]))\n",
    "    scores = {word: tfidf(word, doc, doclist) for word in doc.words}\n",
    "    sorted_words = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for word, score in sorted_words[:10]:\n",
    "        print(\"\\t{}, TF-IDF: {}\".format(word, round(score, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
